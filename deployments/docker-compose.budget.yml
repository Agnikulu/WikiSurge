version: '3.8'

# =============================================================================
# WikiSurge Budget Docker Compose - All Features, Minimal Resources
# =============================================================================
# Target: 4GB RAM server (~$9/month Hetzner CX21)
# Usage:
#   docker-compose -f deployments/docker-compose.budget.yml up -d
#
# Key optimizations:
#   - Elasticsearch with 256MB heap (6h retention)
#   - Single replicas for processor/API
#   - Reduced memory limits across all services
#   - 6-hour retention for all data
# =============================================================================

networks:
  wikisurge-budget:
    driver: bridge

volumes:
  kafka-data:
  redis-data:
  es-data:
  prometheus-data:
  grafana-data:

x-logging: &default-logging
  driver: json-file
  options:
    max-size: "5m"
    max-file: "2"

x-restart-policy: &default-restart
  restart: unless-stopped

services:
  # ---------------------------------------------------------------------------
  # Kafka (Redpanda) - Message Broker (Budget)
  # ---------------------------------------------------------------------------
  kafka:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    container_name: wikisurge-kafka
    <<: *default-restart
    command:
      - redpanda
      - start
      - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092
      - --advertise-kafka-addr internal://kafka:9092,external://localhost:19092
      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
      - --advertise-pandaproxy-addr internal://kafka:8082,external://localhost:18082
      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
      - --rpc-addr kafka:33145
      - --advertise-rpc-addr kafka:33145
      - --smp 1
      - --reserve-memory 0M
      - --memory 400M
      - --overprovisioned
      - --node-id 0
      - --check=false
      # Short retention for budget
      - --set redpanda.log_retention_ms=7200000
    ports:
      - "19092:19092"
      - "18081:18081"
      - "18082:18082"
    volumes:
      - kafka-data:/var/lib/redpanda/data
    networks:
      - wikisurge-budget
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
    healthcheck:
      test: ["CMD-SHELL", "rpk cluster health --api-urls localhost:9644 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Redis - In-Memory Store (Budget)
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: wikisurge-redis
    <<: *default-restart
    command: >
      redis-server
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --appendonly no
      --save ""
      --loglevel warning
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - wikisurge-budget
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Elasticsearch - Search (Budget: 256MB heap, 6h retention)
  # ---------------------------------------------------------------------------
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: wikisurge-elasticsearch
    <<: *default-restart
    environment:
      - node.name=elasticsearch
      - cluster.name=wikisurge-budget
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      - xpack.ml.enabled=false
      # Budget heap settings - 256MB
      - ES_JAVA_OPTS=-Xms256m -Xmx256m -XX:+UseG1GC -XX:MaxGCPauseMillis=200
      # Reduced buffer sizes for budget
      - indices.memory.index_buffer_size=10%
      - thread_pool.write.queue_size=200
      - indices.queries.cache.size=5%
      - indices.fielddata.cache.size=5%
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    ports:
      - "9200:9200"
    volumes:
      - es-data:/usr/share/elasticsearch/data
    networks:
      - wikisurge-budget
    deploy:
      resources:
        limits:
          memory: 768M
          cpus: '0.5'
        reservations:
          memory: 384M
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 90s
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Ingestor - Wikipedia SSE Consumer (Budget)
  # ---------------------------------------------------------------------------
  ingestor:
    build:
      context: ..
      dockerfile: deployments/Dockerfile.ingestor
    image: wikisurge/ingestor:budget
    container_name: wikisurge-ingestor
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - CONFIG_PATH=/app/configs/config.budget.yaml
      - LOG_LEVEL=warn
      - LOG_FORMAT=json
      - GOGC=50
    volumes:
      - ../configs:/app/configs:ro
    networks:
      - wikisurge-budget
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
        reservations:
          memory: 64M
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:2112/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Processor - Single Replica (Budget)
  # ---------------------------------------------------------------------------
  processor:
    build:
      context: ..
      dockerfile: deployments/Dockerfile.processor
    image: wikisurge/processor:budget
    container_name: wikisurge-processor
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    environment:
      - CONFIG_PATH=/app/configs/config.budget.yaml
      - LOG_LEVEL=warn
      - LOG_FORMAT=json
      - GOGC=50
    volumes:
      - ../configs:/app/configs:ro
    networks:
      - wikisurge-budget
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:2112/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # API - Single Replica (Budget)
  # ---------------------------------------------------------------------------
  api:
    build:
      context: ..
      dockerfile: deployments/Dockerfile.api
    image: wikisurge/api:budget
    container_name: wikisurge-api
    restart: always
    depends_on:
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    environment:
      - CONFIG_PATH=/app/configs/config.budget.yaml
      - API_PORT=8080
      - LOG_LEVEL=warn
      - LOG_FORMAT=json
      - GOGC=50
    ports:
      - "8080:8080"
    volumes:
      - ../configs:/app/configs:ro
    networks:
      - wikisurge-budget
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
        reservations:
          memory: 64M
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Frontend - React Dashboard (Budget)
  # ---------------------------------------------------------------------------
  frontend:
    build:
      context: ..
      dockerfile: deployments/Dockerfile.frontend
    image: wikisurge/frontend:budget
    container_name: wikisurge-frontend
    <<: *default-restart
    depends_on:
      api:
        condition: service_healthy
    ports:
      - "80:80"
    networks:
      - wikisurge-budget
    deploy:
      resources:
        limits:
          memory: 64M
          cpus: '0.1'
        reservations:
          memory: 32M
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:80/"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Prometheus - Metrics (Budget: 6h retention)
  # ---------------------------------------------------------------------------
  prometheus:
    image: prom/prometheus:latest
    container_name: wikisurge-prometheus
    <<: *default-restart
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=6h'
      - '--storage.tsdb.retention.size=500MB'
      - '--web.enable-lifecycle'
      # Budget: longer scrape intervals
      - '--query.max-samples=50000'
    ports:
      - "9090:9090"
    volumes:
      - ../monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - wikisurge-budget
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Grafana - Dashboards (Budget)
  # ---------------------------------------------------------------------------
  grafana:
    image: grafana/grafana:latest
    container_name: wikisurge-grafana
    <<: *default-restart
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-wikisurge123}
      - GF_LOG_LEVEL=warn
      - GF_LOG_MODE=console
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
      # Budget: disable unused features
      - GF_EXPLORE_ENABLED=false
      - GF_ALERTING_ENABLED=false
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ../monitoring/grafana-provisioning:/etc/grafana/provisioning:ro
    networks:
      - wikisurge-budget
    depends_on:
      prometheus:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.15'
        reservations:
          memory: 64M
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # ES Index Cleanup - Cron job to manage short retention (Budget)
  # ---------------------------------------------------------------------------
  es-curator:
    image: alpine:latest
    container_name: wikisurge-curator
    <<: *default-restart
    entrypoint: /bin/sh
    command:
      - -c
      - |
        apk add --no-cache curl jq
        while true; do
          echo "[$(date)] Running ES cleanup for 6h retention..."
          # Get all indices and delete those older than 6 hours
          CUTOFF=$(date -d '6 hours ago' +%Y.%m.%d.%H 2>/dev/null || date -v-6H +%Y.%m.%d.%H)
          # Force merge to reduce segments (saves memory)
          curl -sf -X POST "http://elasticsearch:9200/wikipedia-edits-*/_forcemerge?max_num_segments=1" 2>/dev/null || true
          # Clear caches to free memory
          curl -sf -X POST "http://elasticsearch:9200/_cache/clear" 2>/dev/null || true
          sleep 3600  # Run every hour
        done
    networks:
      - wikisurge-budget
    depends_on:
      elasticsearch:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 32M
          cpus: '0.05'
    logging: *default-logging
